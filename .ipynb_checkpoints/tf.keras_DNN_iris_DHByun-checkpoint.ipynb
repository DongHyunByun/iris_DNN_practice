{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.4 3.1 5.5 1.8]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers  #모듈(변수나 함수를 포함)만 불러오기\n",
    "\n",
    "csv = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "X = csv[[\"sepal_length\", \"sepal_width\",\"petal_length\",\"petal_width\"]].as_matrix()\n",
    "\n",
    "print(X[0])\n",
    "# 레이블\n",
    "bclass = {\"Iris-virginica\":[1,0,0], \"Iris-setosa\":[0,1,0], \"Iris-versicolor\":[0,0,1]}\n",
    "y = np.empty((150,3))     # 2000x3 크기의 다차원 벡터 생성\n",
    "\n",
    "for i, v in enumerate(csv[\"iris_type\"]): #i는 index(숫자), v는 label의 원자값(문자열)들어감\n",
    "    y[i] = bclass[v]                 #\"thin'이면, y[i]=[1,0,0] 와 같이 할당\n",
    "\n",
    "\n",
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기 --- (※2)\n",
    "X_train, y_train = X[0:100], y[0:100]\n",
    "X_test,  y_test  = X[100:150], y[100:150]\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#순차적 계층화 준비\n",
    "model = tf.keras.Sequential()  \n",
    "\n",
    "# -------------------input node:4, hidden node:15---------------------------\n",
    "model.add(layers.Dense(15, input_shape=(4,)))  \n",
    "model.add(layers.Activation('relu'))  \n",
    "model.add(layers.Dropout(0.1))        \n",
    "\n",
    "# ------------------------hidden node : 15-------------------------------------\n",
    "model.add(layers.Dense(15))       \n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "#-------------------------output node : 3-------------------------------------\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation('softmax')) \n",
    "\n",
    "# 모델 구축하기\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  #다중 교차엔트로피\n",
    "    optimizer=\"rmsprop\",   #최적화 기법 중 하나\n",
    "    metrics=['accuracy'])  #정확도 측정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/300\n",
      "80/80 [==============================] - 0s 263us/sample - loss: 0.0613 - accuracy: 0.9750 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0780 - accuracy: 0.9625 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0673 - accuracy: 0.9750 - val_loss: 0.0700 - val_accuracy: 0.9500\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0625 - accuracy: 0.9750 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0423 - accuracy: 0.9875 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0597 - accuracy: 0.9875 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0765 - accuracy: 0.9750 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0688 - accuracy: 0.9875 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0859 - accuracy: 0.9750 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0606 - accuracy: 0.9750 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0614 - accuracy: 0.9750 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0804 - accuracy: 0.9625 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0672 - accuracy: 0.9750 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0848 - accuracy: 0.9625 - val_loss: 0.0444 - val_accuracy: 0.9500\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0671 - accuracy: 0.9750 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0427 - accuracy: 0.9750 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0656 - accuracy: 0.9875 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0617 - accuracy: 0.9750 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0569 - accuracy: 0.9875 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0574 - accuracy: 0.9750 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.1000 - accuracy: 0.9625 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0834 - accuracy: 0.9750 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0638 - accuracy: 0.9875 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0781 - accuracy: 0.9750 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0660 - accuracy: 0.9875 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0795 - accuracy: 0.9750 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0625 - accuracy: 0.9750 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0585 - accuracy: 0.9750 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0840 - accuracy: 0.9750 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0622 - accuracy: 0.9875 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0631 - accuracy: 0.9875 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0636 - accuracy: 0.9750 - val_loss: 0.0639 - val_accuracy: 0.9500\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0783 - accuracy: 0.9625 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0908 - accuracy: 0.9625 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0547 - accuracy: 0.9875 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0785 - accuracy: 0.9625 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0797 - accuracy: 0.9750 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0743 - accuracy: 0.9875 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0782 - accuracy: 0.9625 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0674 - accuracy: 0.9875 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0746 - accuracy: 0.9750 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0481 - accuracy: 0.9875 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0984 - accuracy: 0.9625 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0781 - accuracy: 0.9875 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0607 - accuracy: 0.9875 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 300us/sample - loss: 0.0711 - accuracy: 0.9875 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.0718 - accuracy: 0.9750 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0917 - accuracy: 0.9500 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0693 - accuracy: 0.9875 - val_loss: 0.0159 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0516 - accuracy: 0.9875 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0783 - accuracy: 0.9750 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0669 - accuracy: 0.9875 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0585 - accuracy: 0.9625 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0872 - accuracy: 0.9625 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0669 - accuracy: 0.9750 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0902 - accuracy: 0.9625 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0210 - accuracy: 0.9875 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0571 - accuracy: 0.9875 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0782 - accuracy: 0.9750 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0545 - accuracy: 0.9750 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0688 - accuracy: 0.9875 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0819 - accuracy: 0.9750 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0698 - accuracy: 0.9750 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0544 - accuracy: 0.9875 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0505 - accuracy: 0.9875 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0610 - accuracy: 0.9750 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0919 - accuracy: 0.9750 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0545 - accuracy: 0.9875 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0542 - accuracy: 0.9875 - val_loss: 0.0403 - val_accuracy: 0.9500\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0590 - accuracy: 0.9625 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.1105 - accuracy: 0.9750 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0478 - accuracy: 0.9875 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0694 - accuracy: 0.9750 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0549 - accuracy: 0.9875 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0955 - accuracy: 0.9750 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0676 - accuracy: 0.9750 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0817 - accuracy: 0.9750 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0634 - accuracy: 0.9875 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0765 - accuracy: 0.9875 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0727 - accuracy: 0.9750 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0582 - accuracy: 0.9750 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0522 - accuracy: 0.9875 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0690 - accuracy: 0.9750 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.0451 - val_accuracy: 0.9500\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 500us/sample - loss: 0.0837 - accuracy: 0.9500 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0357 - accuracy: 0.9875 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0497 - accuracy: 0.9750 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0470 - accuracy: 0.9875 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0541 - accuracy: 0.9750 - val_loss: 0.0410 - val_accuracy: 0.9500\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0660 - accuracy: 0.9750 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0638 - accuracy: 0.9750 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0595 - accuracy: 0.9875 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0576 - accuracy: 0.9875 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0514 - accuracy: 0.9750 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0904 - accuracy: 0.9625 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0829 - accuracy: 0.9750 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0586 - accuracy: 0.9875 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0488 - accuracy: 0.9875 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0592 - accuracy: 0.9875 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0838 - accuracy: 0.9625 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0509 - accuracy: 0.9875 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0773 - accuracy: 0.9625 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0645 - accuracy: 0.9750 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0711 - accuracy: 0.9625 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0794 - accuracy: 0.9625 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0600 - accuracy: 0.9750 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0552 - accuracy: 0.9875 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0764 - accuracy: 0.9750 - val_loss: 0.0546 - val_accuracy: 0.9500\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0786 - accuracy: 0.9750 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0688 - accuracy: 0.9875 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0428 - accuracy: 0.9875 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0701 - accuracy: 0.9750 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0558 - accuracy: 0.9875 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.00 - 0s 213us/sample - loss: 0.0535 - accuracy: 0.9750 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0702 - accuracy: 0.9625 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0616 - accuracy: 0.9875 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0794 - accuracy: 0.9750 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0438 - accuracy: 0.9875 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0701 - accuracy: 0.9750 - val_loss: 0.0492 - val_accuracy: 0.9500\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0669 - accuracy: 0.9875 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0715 - accuracy: 0.9750 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0541 - accuracy: 0.9875 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0575 - accuracy: 0.9875 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0859 - accuracy: 0.9625 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0514 - accuracy: 0.9875 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0612 - accuracy: 0.9750 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0686 - accuracy: 0.9750 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0534 - accuracy: 0.9875 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0424 - accuracy: 0.9750 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0366 - accuracy: 0.9875 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0591 - accuracy: 0.9875 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0581 - accuracy: 0.9875 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0576 - accuracy: 0.9875 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0636 - accuracy: 0.9875 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0776 - accuracy: 0.9875 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0738 - accuracy: 0.9750 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.1111 - accuracy: 0.9750 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0866 - accuracy: 0.9500 - val_loss: 0.0555 - val_accuracy: 0.9500\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.0640 - accuracy: 0.9625 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0617 - accuracy: 0.9875 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0742 - accuracy: 0.9875 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0610 - accuracy: 0.9875 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0668 - accuracy: 0.9875 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0594 - accuracy: 0.9875 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0950 - accuracy: 0.9625 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0585 - accuracy: 0.9875 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0496 - accuracy: 0.9750 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.1208 - accuracy: 0.9625 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0496 - accuracy: 0.9750 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.1023 - accuracy: 0.9625 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0860 - accuracy: 0.9625 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0708 - accuracy: 0.9750 - val_loss: 0.0409 - val_accuracy: 0.9500\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0524 - accuracy: 0.9875 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0692 - accuracy: 0.9625 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0535 - accuracy: 0.9875 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0658 - accuracy: 0.9750 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0777 - accuracy: 0.9750 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0589 - accuracy: 0.9875 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.0627 - accuracy: 0.9875 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0698 - accuracy: 0.9750 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0543 - accuracy: 0.9750 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0540 - accuracy: 0.9875 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0600 - accuracy: 0.9750 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0603 - accuracy: 0.9750 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0722 - accuracy: 0.9875 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.1297 - accuracy: 0.9500 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0626 - accuracy: 0.9875 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.0662 - val_accuracy: 0.9500\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0767 - accuracy: 0.9625 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0642 - accuracy: 0.9750 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0499 - accuracy: 0.9875 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0755 - accuracy: 0.9750 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0800 - accuracy: 0.9750 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0727 - accuracy: 0.9750 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0713 - accuracy: 0.9875 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0580 - accuracy: 0.9875 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0625 - accuracy: 0.9875 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0672 - accuracy: 0.9750 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0948 - accuracy: 0.9625 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0776 - accuracy: 0.9750 - val_loss: 0.0485 - val_accuracy: 0.9500\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0791 - accuracy: 0.9750 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0429 - accuracy: 0.9875 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0472 - accuracy: 0.9750 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0567 - accuracy: 0.9750 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0757 - accuracy: 0.9625 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0490 - accuracy: 0.9875 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0652 - accuracy: 0.9875 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0898 - accuracy: 0.9625 - val_loss: 0.0490 - val_accuracy: 0.9500\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0761 - accuracy: 0.9625 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0718 - accuracy: 0.9625 - val_loss: 0.0442 - val_accuracy: 0.9500\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0664 - accuracy: 0.9750 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0639 - accuracy: 0.9875 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0609 - accuracy: 0.9750 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0728 - accuracy: 0.9875 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0727 - accuracy: 0.9750 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.0497 - val_accuracy: 0.9500\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.0266 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0764 - accuracy: 0.9875 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0896 - accuracy: 0.9500 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0525 - accuracy: 0.9875 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0627 - accuracy: 0.9750 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0672 - accuracy: 0.9750 - val_loss: 0.0467 - val_accuracy: 0.9500\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0771 - accuracy: 0.9750 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0723 - accuracy: 0.9750 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0540 - accuracy: 0.9750 - val_loss: 0.0466 - val_accuracy: 0.9500\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0593 - accuracy: 0.9625 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 275us/sample - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0491 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0661 - accuracy: 0.9750 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0516 - accuracy: 0.9750 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0615 - accuracy: 0.9750 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0839 - accuracy: 0.9750 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0470 - accuracy: 0.9750 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0508 - accuracy: 0.9750 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0478 - accuracy: 0.9875 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0554 - accuracy: 0.9875 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0642 - accuracy: 0.9625 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0896 - accuracy: 0.9625 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0675 - accuracy: 0.9625 - val_loss: 0.0425 - val_accuracy: 0.9500\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.0426 - val_accuracy: 0.9500\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0590 - accuracy: 0.9875 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0650 - accuracy: 0.9875 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0556 - accuracy: 0.9875 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0746 - accuracy: 0.9750 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0693 - accuracy: 0.9875 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.0627 - accuracy: 0.9875 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0531 - accuracy: 0.9875 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0529 - accuracy: 0.9750 - val_loss: 0.0606 - val_accuracy: 0.9500\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0600 - accuracy: 0.9750 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0631 - accuracy: 0.9875 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0619 - accuracy: 0.9750 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0451 - accuracy: 0.9875 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0590 - accuracy: 0.9750 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0823 - accuracy: 0.9625 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0582 - accuracy: 0.9750 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0683 - accuracy: 0.9875 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0551 - accuracy: 0.9875 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0578 - accuracy: 0.9875 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0609 - accuracy: 0.9875 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0581 - accuracy: 0.9875 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0743 - accuracy: 0.9875 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0529 - accuracy: 0.9875 - val_loss: 0.0579 - val_accuracy: 0.9500\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0664 - accuracy: 0.9750 - val_loss: 0.0264 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0606 - accuracy: 0.9875 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0747 - accuracy: 0.9750 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0824 - accuracy: 0.9875 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.1050 - accuracy: 0.9750 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0533 - accuracy: 0.9875 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0619 - accuracy: 0.9875 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0569 - accuracy: 0.9875 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0882 - accuracy: 0.9625 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0385 - accuracy: 0.9875 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0647 - accuracy: 0.9625 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.0652 - accuracy: 0.9875 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0713 - accuracy: 0.9875 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0610 - accuracy: 0.9875 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0461 - accuracy: 0.9875 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0798 - accuracy: 0.9625 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0647 - accuracy: 0.9625 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0673 - accuracy: 0.9750 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0683 - accuracy: 0.9875 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.0661 - accuracy: 0.9750 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0735 - accuracy: 0.9625 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 0.0647 - accuracy: 0.9875 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 60us/sample - loss: 0.0984 - accuracy: 1.0000\n",
      "test_loss:  0.05824312150478363\n",
      "test_acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "#데이터 훈련\n",
    "'''\n",
    "batch_size       : 몇번마다 수정할 것인가.\n",
    "epochs           : 최대 몇번 반복할 것인가(early stopping에 걸릴 수 있음)\n",
    "valdiation_split : 데이터가 잘 학습되었는지 확인 (training set에서 몇프로 만큼?)\n",
    "callbacks        : moniotr(val_loss혹은 val_accuracy) 가 patience만큼 개선되지 않으면 종료\n",
    "verbose          : 0:미출력, 1:개선되는과정 출력, 2:매 에포크마다 출력\n",
    "'''\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=30,  \n",
    "    epochs=300,    \n",
    "    validation_split=0.2,  \n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=500)],  \n",
    "    verbose=1) \n",
    "\n",
    "# 테스트 데이터로 평가하기 \n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('test_loss: ', score[0])\n",
    "print('test_acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                75        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 48        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 363\n",
      "Trainable params: 363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3hcxfWw36NmSZbcC8Zyx+CGCzY1JpgaTOimBkjoSYhpIQRCCJ0vpNIJmBIC4UeJaQZMxwWDDdjGxrbcu+Qmy7asLq32fH/Mrna12pVWZS3Je97n2WfvnTkzc+7d3Xt2Zs6cEVXFMAzDMFoTCS2tgGEYhmGEYsbJMAzDaHWYcTIMwzBaHWacDMMwjFaHGSfDMAyj1ZHU0go0lISEBE1LS2tpNQzDMNoUJSUlqqptpkPS5oxTWloaxcXFLa2GYRhGm0JESltah4bQZqyoYRiGET+YcTIMwzBaHWacDMMwjFZHm5tzCkdlZSU5OTmUlZW1tCptltTUVLKyskhOTm5pVQzDMGJnnEQkFZgNtPO1M1VV7w6RaQe8BIwF8oELVXVDQ9vKyckhMzOT/v37IyJN1j3eUFXy8/PJyclhwIABLa2OYRhGTIf1yoETVHUUMBo4VUSOCpG5CtitqgcBDwN/aUxDZWVldO3a1QxTIxERunbtaj1Pw4hjROQFEdkhIksj5IuIPCYia0TkBxE5LJb6xMw4qaPId5rse4WGQD8L+I/veCpwojTSwphhahp2/wwj7nkROLWO/InAYN/rWuBfsVQmpnNOIpIILAAOAp5U1W9CRHoDmwFU1SMiBUBXYGdz61JVVYrHs4vk5B4kJLh5lU0Fmzj82cMpqSyh3FNOt/Ru7CjewQ1H3sAby94gtzCXI3sfyTe533DywJP5dN2nDO8+nHEHjuM/i//DxSMuZnfZbg4/8HAAvlj/BaN6juKp+U+RnpxOSWUJE/pPYO2utWzeu5leGb3YWrQVgPOHnc+QbkP4cM2HbC7YzLVjr63W9b1V73FC/xNon9K+Om3z3s1sKthEXnEepww6hQ9WfwDAARkHcGzfY6vlFmxdwIjuI/hk3Sc16pi9cTZje42loLyANbvWUOmtZHPBZlISU0hNSuXcoeeyc+dOchblUFhRSGpSKp1SO5Hi7Ujpzh4MGeLqL/eUM33NdM4Zck7U976iqoL3V73PuUPPbcQnV5uiIsjJhSGHNEt1EVmxArL6QEb7+mWDqaqCJUtg1CgQgSU7lpAgCQzvPryW7OpdqykoK2DcgePIXg79+0F6OsyeDT16UH3fG8PGja6u7t0bX8ezC5+ld2ZvTht8WoPKrVgJWb0hI6N2Xl2f3xvL3qBfp350S+/GoM6DomqrrBzWrIYRIwJpU7OnctYhZ5GcmFzr8wDYVbqL+Vvmc8qgUxp0XZH4cM2HTDxoYlSy76x4h1MPOpXUpNQGtzO+7/hm0zkUVZ0tIv3rEDkLeEndPkvzRKSTiPRS1a2x0Ef2xX5OItIJeBu4XlWXBqUvA36iqjm+87XAEaqaH1L+WpylJiUlZWx5eXmN+pcvX87QoUPr1KGychdlZetITx9OYqKLMCH3Nk9vQRC0Vqew6fUIAf3qqz+SDs2im0r1jzqSfnUWb0SZOuvzVRfrzl5j2wkt57/+cNcenBdcrjmusal1hH5vGvLZ1dV2pLzGthfpfgfXoVqzveb8Tjakrqa2e9uPbuPPJ/25weUARKQCWBKUNEVVp4TI9AfeV9URhCAi7wMPqeoc3/nnwG2qOr9RCtXDPvHWU9U9IjIT12UMHs/MAfoAOSKSBHQEdoUpPwWYAtC+ffumPmmbVjwM636xjuN/cTwbTtjQoHI5N+eQ9XAWAC+d/RKXjbqMhVsXMnbKWEb2HMniXy2ulq3LkFb+qZKkhCRmb5zNcS8eV50+rPswll23jO+3fs9hUw6jQ7sO7C3fG7aO9y5+jz4VfRj95ujamfd62VMAHTrAKS+fwqfrPuWTSz/h5EEnR3WdZ7x6Bu+vep9pF03jjEPOiKpMXWRmun/fu3ZDp05Nri4su3ZB167Qvr1rqyFceSX8+9/w7HNw1VWBz857t7eWrD9v01Ve+vSB3r1hwwbwO016m/B19T+MG1vHKz+8wqVvXwrA5ps3k9UhK6pyu3dDly7QsSPs2RNZr7JySEkJpD/57ZNM/nBy9Xm4+xWOww+H+fNh3jdwxBHw+tLXuejNi7hw+IW8dt5rTJ4MTz4Jjz0Ok33VJ96XiFe9DbquSNz5xZ08+OWD3H/8/dz54zvrlJ2xfgYnvHQCE/pPYMYvZjSp3UbgUdVxTSgf7iEUs95NzOacRKS7r8eEiKQBJwErQsSmAb/wHZ8HfKEx68rF7m/27bffzpbcLQ0ulyCB25+3M4+hQ4fywP0PALBu3TpKS6OLNjJm9BjOOecciotqhnVau3YtF110UXU7RfU8Zeuad2pNGyYn+f5ShXSgm5Wm1O3xuPekBvz1q6xsnrZjRfB3tT78+td3/d7obE+Tqavn2JDrMqo7E36ygIY/+KIklj2nXsB/fPNOCcAbqvq+iNwHzFfVacDzwMsisgbXY7qoqY2uXn0TRUWLaqWrevB6S0lMbE9z2+SHHnqIb3/+LetZ36ByoT+MVatWs67kFbjybUpLD+Tkk7cyZ85Ann++7nq+/eYHevQo5N2Fi+DKQHp52SBef/01Xp+xBK6DdinplGp4A3XWWeBdORzuDpsd6KFcBgyCSy6BvNAZxEhcDBwCZ54JrIqyTBQccEDz1RWJ4uLGD4tdfrl7cY87D1uPL2/gQPeem1tznqY5hi4bXcehwCR32PvABGhgDzI/v+62a8VvPhz4aeC0oXofeaTvYDhwPrz+Orx+fiD/+uvdC4C7gITGXVctTgB+DH/6E/xpdj2y/YHLYeYMkMsb3tTkyfD44w0v10xMAyaLyGvAkUBBrOabIIbGSVV/AMaESb8r6LgMOD9Upk3SiJ5FqHEaMGAwa4sSAajypPLVV+6JdfXVVD/EwrFxo1BU1AE6pYQX8AUiLivzulVnYfB6A3LRkJcXtaixP9B2glk3jDZ2XdOmxc44icirwASgm4jk4P6qJgOo6tPAdOA0YA1QAlwRG00c+0WEiGAGD34kbHpl5R7KytaQnj7U13sCpjXfUF9jJjdDjVNKSuO2Aqmq8h1E+qH50pOSEqkML4GzrtFcQysa3zP2HW3sIe6I4rvaxq6rIUPFDUVVL64nX4HfxE6DmrStT6aVkpmZSUlxSYPLbdsWuP1z56aSl/erWjJff11/PX/8o++gHuNUWWlrmYxG0sYe4lGzv17XfoB9Ms1A165dGT0qjJdbPYwYFrj9U/+Xyc6d19aS+dGP6q/n3Xd9B/UYJyM+uOyyGFS6v36H2th1xeSzbaW0rU+mCcR6TcxfHmpE5KXm/mGYcWpWFi5subZzchpf9sUXYVUEx5PvvoPVq2HRIud+/eWXtWXOCbe+Oug7dM01geQbb4Q1a2DSpPDtXXhh/fr6FwlPrGcN67x59dcFcP/9Nc/vuafmeY05m6Dr+uEHd3+Cee45+PZbGBfBAXvs2Oh08vNwmFmHzz6LLH/nne66P//cfV53R3BY2h+Jo6eW3zrFZs6kUS6pZpxaNWNqufPsOw48sPFlExJg8ODweePGwUEHuWgJY8fC+PHQrVtNmWOPDVMw6DsU/EBOToZBgyL38KOJI+xfP9+/HtloDUHotXfuXPO8X7+gk6DrOvTQ2kZo2DC3jmr8+PBt9elT8zz0XoYyaqR7bx8UdSSrjmVW/fs7L8QTTnDXH09RxvY7h4j6iMV6nYcegk2lCQ039WacjAi05EPIv06rBhG+Q2FlQ/KDI17URUI9X9PExPrraDDN/NtozPMlteFRjOICe2o1A3/4A/zrKes57UsOPTRwfG4DQvYdf7x7D/43/dvfBo4zM937b3w+Sb//fe06rruu7jbuuity3n/+Ezj+978DxwcfXDNaQjCP+IaCbrnFDbkF90ZOPx3OPtsN0wH89a+BvOeeq1nP22+Hr/+jjwLHQ4bAtbWnPpl4auA7dMkl8NZb7viOO9z7VVfB+ee7P2pXXQU9e7r0224LGJ3jjqMGPXu6ep5/3tU5aGDN/CefhCt8zsoTJoQ32HfcUXMexq8PBOSDhyFD8/y/jQceCOT961/wu9+5ev09KX+9jzwCI329n//+Fx591PWuAMaOg/feC9Tz4ouBz/Tpp+GZZwJ5w4a7z/y66wK95EsvdT1acGvdUlLgoiav/Gy77H9PrYjEOhBbI+rfz43Tq6/WLxPOG3F0GN8SVffy5734YiAo6gMPRPePVRW++MK9v/mmSzvuOPjHPwIyN9/s8p94wp3/5S+167799vDDWD/7mZO991545x2XduaZNWV+/vPAcbBRXbkycm/pxhtdvX//u3uYv/GGSz/sMPcwfPtt91BThVtvDZS76iq3uBpcubPPDl//2LHwy1+64xtucGGHVN3D18/JJ7nv0OTJ7sF5zjlOxj9f1KGD0+u225xR3LbN5XfrFjBOH3zg0n7yE3f+4ouunoMOcm2F7nN53XXwwguuzIyQSD/+78ODD7r7Aq6tBx8MyJx/gZNJS3Pvp58eyPPf67POTEA1yOMV+NWv4G9/g5deCujUvbur48YbYfFid3zJJdC3b2CO7uyzAkPBCQnwi1+4aBmq7v4GG/327d1n/uSTrg1VePll9ydDFQoLXdn2DQw6vD8RR8bJj3vSVFZFXvHTOMw4NYZ2YRYF1xXWpkbwziYM0TYlKGpCQvMMuzV2mKo6wGkU1+8Pi1TfBsf1yUkTHhV+ff3X6x8KDL3+xt5T//elMffTW9W8v42YDD3GKa33qRVjUh6IMIbSWCobsYA22GgU9nbvZb44QVtD9vEqz4xehx2+cYatvhlkj29Qe93JUBBh9rUoQiyg0pDZ5O2+cYeSBuzDsMM3Blfcs0byEUeEH8ryegPhfOoiGgMTrhcGgX/8ofmDIuzSEKxPQkLzOEuELqgM54gQTp8uXdx7NDoM9+3S0bt33XIHH+zeg4cMgwOi9u8vNeQagt+ZwN+D8g+L9az5daBfp340Bv8fnKN8W5n27uAudli3YRHLjOzsur7DhjX9X0b/Tv0B6Nuxb7VxOuaY8LLd27sv3sgeI5vc7n6PqrapV3p6uoaSnZ1dKy2UysoC3bv3O62s3KuqqtyDcg964n9O1Ns/vV0fm/dYddoV71yh3IP2/FtPnb5quj7+zeOavSNbf/72z5U+c5TOa/ThuQ8rmblKl1VaPcgw8BMlY6tyxGPKSbcp4/+fcsi7Lv3IR5WDpis/vk+5+Ayl0zpXptd8ZfD7gTpQpfc8Jam0Zlr77Uq3bKXPV0pimTLoI2XMc8oBC2vKHTRdab9NL751npJUEkgf8LmStlNJz1N6LNGf/36RXvfINGX4a0rf2UFtf6Nkfe2uK+trpeuKmvUnVDgdgtOCXv/9b+D4tddUf/hBNXdrpT70f3Oq0+fOVX3gAdUtW1RXrgzIv/qqex82THXnTld2wwbVdesCn+OYMU5m/nzVwYPd8YoVLm/tWtVp01RXrVL95BPV1atVd+9WfeMN1dzc2t+Jr75SLS93x34dvN7w35916wIyW7e6cl995dp88EGX/rOfBeTfecelnXmm6vrd63XO0g3V17FlS0DnD+fk6MKNq1TV1fvcc05/VXf9+fnh9Zk7V7W0tL5vvWpFheqcOfXLeTyqs2fXTv9g1Qf6Xe53qqo6a5ZqVVX9dYWyd6/qggWBc/+9C8cDL8/Sd75cobl7w3xg6j6HDRtqp3/7rWpRUeD8y41fqqfKU0Pm9NPdZzJtmmpBWYE+P32hVlY29GpqU+4p1w9WfaAVngpVVV24ULWgILL8V5u+0nJPedMbbiBAsbaCZ3i0rxZXoKGvxhunvT7j5L41fkMUjD9t8geTlXvQR+Y+Uqse/wMq+Lg1vn7727rz/Ywb17ztFhQEjl9/PfK987N+vUvr21c1O9sdDxkS+XM87DCtZZxWrqz346+XcLqF0qOHk9m2rWb6yy+79EsuCaQFGyejdRBsnOKRtmac4nZYry78a5a0jjVRL7ywr7SJLc0dq0sj37Kw+If1KioCwz7VsQLraaehbTWV+trb1/oYxv7M/rfO6aabAn61QSRqFWneEhIT0kESwedSzIQJASFfmrz5JvQBfeIJuP0dNzHxSM2l3VddFRv1m4vLLnNbdAe7yJ56ak23YXCu0g1xxZ4wAWbOdMc9e8L27TXzg72Lopng7t7dzRn85S/O8ykhofYK/2CC63zwQedqW9cixlgQel1+9/RgF/Ojj3bvN920b3Qy6ue3v4X33w/aWsNo1VjPKQzVSyBk3/4VvuSS6GWvvnoK55zjdrP/5z+LGThwEJMnX1+dP3p07Yf8a6+59+D9gk6OYjPb4IG7GTNgwQKXfuCBtXsLSUkBYxeNcUpOhrIy52KdluZ6TdGEvAG44ALnPJGeHp18rOjd292HYPfyHj1cmt9wGS3P8ce7z6RHj5bWxIiG/a/n9Ej4LTOqPEWUlq4gLW0wSUkdwb/tub8bANVpcv4FMO9h9NfXwTG3xFjhAA0ZFjrggG68+eYM4DwyMtqzePFiPv744+r1OXURvBK/McN6ftfd+lb0xzLKQUsModmwnWHsO6znFAb/3kyhc07BizVjQWgMsLq44IJzGTu2LwBebyFer5dJYaJv+uOWQcBYBLsV+41TjXhj9eCfJ4q0E20sH+L+NsOtj4o1/pX8sdxTxzAMh/3MwiC+p7iGPGV/97vmqb9/f9iwoWbaxIlu3uXJJ2vLp6Yu58QThdTUIdWRDS64YBIdO5Zzyy0vMWpUDhMmXI7X62XIkL5MmnQP4NZJvfEG3Hefi3zQoYNb9X7CCYG6k5JcaJUjj4SZM3O4+ebABM7XXztHhVBGjnShWM47z52vWAGvvBIY1vLfttCe0+LFTYu2DS78z5tvBtbKNBeffhq0FX0EPvzQRZD2rzMyDCN2xI1xasgQU6SeU3Nx3nmBkCt+pk+vLdenD2zeDIcdNpT333dpQ4a4sCdvv/1mdfge6MLCCPs7jBgRCHcD4feD8YeuadeusEa6f1I/HMGhWA45xBlAP5GM08iRTTcqXbuGj/3WVE46qX6ZAw+sGX7IMIzYEUfDetFvmRGu57RrVyx0qht/88FzO9HO97QG4im8v2EYzUsbeMQ1L9HMh4TrOTV0U7H6+OlPw6cHz2dc73O+u+CCQFpbME7+YKPDIkePMQzDqJNW/IhrGKHzQ00hXM8pdI6oIZSV1TxXhWnTIC/PBcEsKQnkFRe7eZ6iIrcGqajIRYL2Eyvj5L/W0lIXDbm0tPF1XXGF07sxcdgMw2g5RORUEVkpImtE5PYw+f1E5HMR+UFEZopIzFYZ7hfGKTU1lfz8/HoMVPRjTM095xTOsywhwYX4T0x063v8pKS4tT/+xazt29ccHvNHT2jOITNVJT8/n9TUVFJTnQ5N3QAtnkP9G0ZbREQSgSeBicAw4GIRCR3/+DvwkqqOBO4D/hwrffYLh4isrCxycnLIy8uLKOP1VlBRsZPkZKEq6LKXL19eS3aXb4Jp+47tQflDa8nVhYiivj2eXB2B8jt35rN8+Y4G1eensvIgIJm1a1dTVlbPNqQNIDU1lax9HWrBMIzWxBHAGlVdByAirwFnAdlBMsOAm33HM4B3YqXMfmGckpOTGRAc6z8MRUWLmT9/IsOHv8meBLeFQ4IkMDRoIdD/zv8fczfP5a7j7qKiXQUPnPoAme2i2KoiDM89J9UhjoLbuPxy+Oc/u9K5c9dG1fvpp/Dss3DiiYPN4cAwjIaQJCLzg86nqOqUoPPewOag8xwgNNjTYmAS8ChwDpApIl1VNb/ZlW3uCv2ISB/gJeAAwIu7EY+GyEwA3gXW+5LeUtX7iAn+EUytHq576eyXakicN+w8zhvmFu/8+6x/N6m1Pn3Cp/+7adUyfHjEIBiGYRh14VHVcXXkh/u7Gzq38TvgCRG5HJgN5ALNN4QTRCx7Th7gFlVdKCKZwAIR+VRVs0PkvlTV08OUb2b8Tg7e6rkpf/TxuigshMzGdZ4MwzDaEjlA8N/qLGBLsICqbgHOBRCRDGCSqhbEQpmYOUSo6lZVXeg7LgSW47qNLYJIYJ2TV70haeGZP99FVfjVrxrWlhkzwzDaIN8Bg0VkgIikABcB04IFRKSbSPW/+j8AMds8aJ9464lIf2AM8E2Y7KNFZLGIfCgiwyOUv1ZE5ovIfI+nsT3I2sN6Uo8H33zf6OwzzzSspXXraqetXw/btjWsHsMwjH2FqnqAycDHuM7EG6q6TETuE5EzfWITgJUisgroCTwYK31i7hDh6/q9CdykqntDshcC/VS1SEROw3l+DA6twzdpNwWgffv2jfTvDhrWI7phvcY6HHTrVjutf//G1WUYhrGvUNXpwPSQtLuCjqcCU/eFLjHtOYlIMs4wvaKqb4Xmq+peVS3yHU8HkkUkzKO9WXTxtxr1sJ5hGIbRMsTMOIl78j8PLFfVf0aQOcAnh4gc4dOn2V0SHQ0f1mtMFIa6dnE1DMMwoiOWw3o/Ai4DloiIf9/0O4C+AKr6NHAe8GsR8QClwEXanHGIahDbYb2f/cxtGxFKNNGuDcMwjJrEzDip6hzqiRmkqk8AUezd2nQaM6zXoG02bITQMAyj2dgvYutFR/TDegcc4IbnGmJwevasee6PLRdpt1jDMAwjMnFknKJfhLt9O9x1V/TG6Zhj4MEQh8qjj4bnn4ennmq0woZhGHFL3Bgn/7qxiootzT6s99VXtaN4i8CVV9qCXMMwjMYQN8ZJfQZp/fo7o/bWC7eY1jAMw4g9cWOcqqqKqo/rGtabNStwbG7hhmEYLUPcGKfU1L6+90F1Duvl5jas3kZHUzIMwzAiEjfGKSmpA4mJGXTrdmbUw3rRkJjY5CoMwzCMEOLGOAGIJKFaFXFYz+OBSy5pCc0MwzCMYOLKOEEiqp6Iw3phdmw3DMMwWoC4Mk4iia7nFGFYz6I8GIZhtA7izDgloeqJOKxnxskwDKN1EGfGKRGoijisZ8bJMAyjdRBnxinJhvUMwzDaAHFmnBJtWM8wDKMNEGfGyfWcwg3rLVsGp5zSUpoZhmEYwcRys8FWiK/nFGZYb8SIltLJMAzDCCXOek6JdS7CNQzDiGdE5FQRWSkia0Tk9jD5fUVkhoh8LyI/iMhpsdIlrp7OIknU5a1nGIYRr4hzZ34SmAgMAy4WkWEhYncCb6jqGOAiIGY71sXVsF61Q0TQsN5BB8H48S2smGEYRstzBLBGVdcBiMhrwFlAdpCMAh18xx2BLbFSJs6MU02HiARJYO1aWLu2YfVs2ABer+33ZBhGmyJJROYHnU9R1SlB572BzUHnOcCRIXXcA3wiItcD7YGTYqEoxJ1xqulK3phhvWOPhX793PGAAc2pnWEYRkzxqOq4OvLDPRA15Pxi4EVV/YeIHA28LCIj1L+bazMSV3NOzlsvsAjXHCIMwzCqyQH6BJ1nUXvY7irgDQBVnQukAt1ioUxcPZ39sfWqHSIasJ9Tu3bu/fLLY6CYYRhGy/MdMFhEBohICs7hYVqIzCbgRAARGYozTnmxUCYOh/WqGjWs16sXrF8fK80MwzBaFlX1iMhk4GMgEXhBVZeJyH3AfFWdBtwCPCsiN+OG/C5X/wO1mYmZcRKRPsBLwAGAFzf59miIjACPAqcBJbgLXRg7nZwruQ3rGYZh1EZVpwPTQ9LuCjrOBn60L3SJZc/JA9yiqgtFJBNYICKf+i7Oz0RgsO91JPAvanuHNBt+h4imDOsZhmEYsSdmXQdV3ervBalqIbAc56oYzFnAS+qYB3QSkV6x0il0m/Zoh/Xuugs++CBWWhmGYRih7JM5JxHpD4wBvgnJCudX3xvYGlL+WuBagJSUlCboUXMRbrTDevfe2+gmDcMwjEYQ80kXEckA3gRuUtW9odlhitSaXFPVKao6TlXHJSU1xZ4m1oxK3oBhPcMwDGPfEVPjJCLJOMP0iqq+FUYkGr/6ZtSnccN6hmEYxr4lZsbJ54n3PLBcVf8ZQWwa8HNxHAUUqOrWCLLNoFPDh/UeeihW2hiGYRiRiOWc04+Ay4AlIrLIl3YH0BdAVZ/GuSyeBqzBuZJfEUN9akclj2JYLzMzlhoZhmEY4YiZcVLVOYSfUwqWUeA3sdIhFJFEvtxRxHu7nvGd12+cYrO8zDAMw6iL+FmF+uGHDPjJ60xdVcS3ud8y7sBx9MqImde6YRiG0QTiJ3xRSQkpG/fi9SZyVNZRzLp8VktrZBiGYUQgfnpOiYkAqFerHSFsyM4wDKN1Ej/Gybc+yqsB45QQxdV37hxLpQzDMIxwxJ1xUo0+MsSVV8KkSbFUyjAMwwhH3Bmn4J5TfVx5pQV8NQzDaAnizjgp0fecbE7KMAyjZYg74+RVSIgypp7XG0uFDMMwjEjEnXFSjT6mnvWcDMMwWob4M05AghknwzCMVk38GCffOif/sN7y5fUXicbV3DAMw6iNiIxoSvn4efwG9ZxEhDvvjCzatavb/Xb8+H2jmmEYRmtARE4VkZUiskZEbg+T/7CILPK9VonInjqqe1pEvhWR60SkU0N1iZ/wRcEOESLUNbI3aZLtfmsYRnwhIonAk8DJuL32vhORaaqa7ZdR1ZuD5K/H7XAeFlUdLyKDgSuB+SLyLfBvVf00Gn3irue0G0gQ6jROhmEYccgRwBpVXaeqFcBrwFl1yF8MvFpXhaq6GrgTuA04DnhMRFaIyLn1KRN3xmmXwO7SPXXOJx111D7SyTAMo/XQG9gcdJ7jS6uFiPQDBgBfRKpMREaKyMPAcuAE4AxVHeo7frg+ZeJuWC9BYVDnfhSE6TllZ0NKCgwcuI91MwzDiD1JIjI/6HyKqk4JOg83nhTJZ/kiYKqqVtXR3hPAs8AdqlpaXaHqFhGpY9bfp2x9AvsNPuOUCGSmpLM3zMfQrx+kp+9btQzDMPYRHlUdV0d+DtAn6DwL2BJB9iLq2ShWVX9cR97LdZWFODROfmbMqC1i81CGYcQx3wGDRWQAkIszQD8LFRKRQ4DOwNy6KvM5Q/wZGPeDqRkAACAASURBVAak+tNVNaqxqfiZc/KtcwJAvWzfXlskNbV2mmEYRjygqh5gMvAxbp7oDVVdJiL3iciZQaIXA6+p1hum4N/AvwAPcDzwElBvj8lP3PWc3Dqn2vd04kTrORmGEd+o6nRgekjaXSHn90RZXZqqfi4ioqobgXtE5Evg7mgKx6VxCoeFKjIMw2hWykQkAVgtIpNxQ4U9oi0c1bCeiNwoIh3E8byILBSRUxqpcMtQwzjVtkRmnAzDMJqVm4B04AZgLHAp8ItoC0c753Slqu4FTgG6A1cADzVMzxYmyCFCwhgni6NnGIbRPPiiTVygqkWqmqOqV6jqJFWdF20d0T6S/bMxp+HCTywmvE986yUhARVnllRrb9RkxskwDKN58K1/GivR7k8UhmjnnBaIyCe4FcF/EJFMoM6t+ETkBeB0YIeq1opOKyITgHeB9b6kt1T1vmgVbxQpSahUWs/JMAwj9nwPvCsi/wOK/Ymq+lY0haM1TlcBo4F1qloiIl1wQ3t18SJuhfBLdch8qaqnR6lD00lOBirDdvnMOBmGYTQrXYB8XLgiPwo0q3E6GlikqsUicilwGPBoXQVUdbaI9I+y/n2CN8V/uTasZxiGEUtUtb4OTJ1Ea5z+BYwSkVHA74HncT2i45rSOHC0iCzGhcj4naouCyckItcC1wKkpKQ0ujFtl+zqs2E9wzCMmCIi/yaMa7SqXhlN+WiNk0dVVUTOAh5V1edFJGqXwAgsBPqpapGInAa8AwwOJ+gLTjgFoH379o12+tZkFyWioODLWnmZmY2t1TAMwwjD+0HHqcA5RI7VV4tojVOhiPwBuAw41ucmmBy1imHwuab7j6eLyFMi0k1Vdzal3rqo8nW6yso21sp7uN4A7oZhGEa0qOqbweci8irwWbTlox3MuhAox6132obb4+Nv0TYSDhE5wO9mKCJH+HTJb0qd9ZGY1hWAjh1qb9jUqcGbCBuGYRgNYDDQN1rhqHpOqrpNRF4BDheR04FvVbUuLzy/lZwAdBORHFw8pWRffU8D5wG/FhEPUApcFEUgwSah7dLcu7aPZTOGYRhxj4gUUnPOaRtuR9yoiMo4icgFuJ7STNzi28dF5FZVnRqpjKpeXFedqvoEztV839HOjet9OH1oddKQIbBixT7VwjAMY79HVZs0kx/tnNMfgcNVdQeAiHTHjR1GNE6tEp+n39q1PauTFi6EsrKWUsgwDGP/RETOAb5Q1QLfeSdggqq+E035aOecEvyGyUd+A8q2GrRdO/eugWW4aWnQuXNLaWQYhrHfcrffMAGo6h6i3C4Dou85fSQiHwOv+s4vJGTPj7aApjgHQ/W2ObtqGIbR1gj3oI16m6ZoHSJuFZFJwI9wc05TVPXtaBtpLWj1At62FbPWMAyjDTJfRP4JPIlzjLgeWBBt4aitmM9n/c16BVsx6nOIQM04GYZhxJjrgT8Br/vOPwHujLZwncYpjCtgdRagqtoh2oZaBdZzMgzD2CeoajFwe2PL1zn5oqqZqtohzCuzzRkmAnNO1nMyDMOILSLyqc9Dz3/e2ee7EBVx5RmgIUFjL7ighRQxDMNohYjIqSKyUkTWiEjYXo+IXCAi2SKyTET+r47quvk89ABQ1d1Aj2h1iXrOaX8g1CFi0KCW08UwDKM14YuZ+iRwMpADfCci01Q1O0hmMPAH4EequltE6jI2XhHpq6qbfGX7E36aKCzxZZxCHCJsmwzDMIxqjgDWqOo6ABF5DTgLyA6SuQZ40tcLImT9ayh/BOaIyCzf+Y/xbX0UDXH1eK6ec/L1nBq/u71hGEabI0lE5ge9Qg1Fb2Bz0HmOLy2Yg4GDReQrEZknIqdGakxVPwLGAStxHnu34OKoRqdstIL7BckpUEl1z8mMk2EYcYRHVcfVkR/uiRg6DJeEiy4+AcgCvhSREcFzS9WViVwN3OiTWwQcBcyl5rbtEYmvnlO7mnNONqxnGIZRTQ7QJ+g8i9qbA+YA76pqpaqux/WKwm4SizNMhwMbVfV4YAyQF60ycfV41uSa+yNu2NAyehiGYbRCvgMGi8gAEUkBLgKmhci8AxwPICLdcMN86yLUV6aqZT7Zdqq6AjgkWmXiyziltfMduJ7Tyy+3oDKGYRitCFX1AJOBj4HlwBuqukxE7hORM31iHwP5IpINzABuVdVIm8Tm+NY5vQN8KiLvEoNt2vcLNDXVd+SMk9fbcroYhmG0NlR1OiFBvVX1rqBjBX7re9VX1zm+w3tEZAbQEfgoWl3iyjiR6nbCtQgRhmEY+w5VnVW/VE3ia1gv1TesZ7H1DMMwWjVxZpxS6xcyDMMwWpw4M041HSIMwzCM1kl8Gad2NqxnGIbRFogv4xTSc3rkkRZUxjAMw4hIXBknQlzJLSq5YRhG6ySujJPNORmGYbQNYmacROQFEdkhIksj5IuIPObb1OoHETksVrr4CfXWs8CvhmEYrZNY9pxeBCKGUwcm4gIGDsbt8fGvGOoC1N5s0DAMw2idxMw4qepsYFcdImcBL6ljHtBJRHrFSh8ATfAZJdsywzAMo1XTknNO0WxsBYCIXOvfIMvj8TRD02aVDMMwWjMtaZyi2djKJapOUdVxqjouKanx4QBdzEKs52QYhtHKaUnjFM3GVs2Khti+ysqdsWzOMAzDaCQtaZymAT/3ee0dBRSo6tZYNljdc/J12pYvvyyWzRmGYRiNJGZbZojIq7h95ruJSA5wN5AMoKpP4/YMOQ1YA5QAV8RKFz/VPSdb52QYhtGqiZlxUtWL68lX4Dexar9u/HNOYae4DMMwjBYmviJEaGjPSfF6m8P7zzAMw2hO4ss4UXPOCaC4eEnLKGMYhmFEJL6Mk9Yexluw4DB27HijBbQxDMMwIhFfxonQdU7ufPfuz1tKJcMwjFaDiJwqIit9MU9vD5N/uYjkicgi3+vqWOkSM4eI1kioK7kfkcR9r4xhGEYrQtyD8EngZNw61O9EZJqqZoeIvq6qk2OtT1z1nKpRM06GYRghHAGsUdV1qloBvIaLgdoixJVxCnWIGDNmBgC5uU+0kEaGYRj7jCR/jFLf69qQ/GjjnU7ybXM0VUT6hMlvHmVjVXFrJNSVPCnJ3MgNw4gbPKo6ro78aOKdvge8qqrlIvIr4D/ACc2lYDBx2nMyDMMwQqg33qmq5qtque/0WWBsrJSJL+MU4hCRUNFyuhiGYbQyvgMGi8gAEUkBLsLFQK0mZM+9M4HlsVImrob1qvEN62Wsgr0jWlgXwzCMVoCqekRkMvAxkAi8oKrLROQ+YL6qTgNuEJEzAQ9uM9nLY6VPXBmnUIeI3p+ks3dECQBebwUJCSkRShqGYez/qOp0XFDu4LS7go7/APxhX+gSn8N6vp5Tt/LDq/M2bLinBTQyDMMwwhFfxinEISJx2Zrq402b/ryv1TEMwzAiEF/GKTRCRG4uSQXB+VX7XCfDMAyjNvFlnMJsNpixPpC/evX1+1gjwzAMIxxxZZwCBIxT+7WB1C1b/kVVVWkL6GMYhmEEE1fGqdZmg927M7Cw5oa9y5adT07OY/tYM8MwDCOY+DJOoZsNjhxJYvaaGjK7dn3AmjU37lvFDMMwjBrEjXHasGcD7618r2biyJGwZAlS2TI6GYZhGOGJG+P0Xe533DXTt5asuId7P+YYKCujb95JLaeYYRiGUYu4MU4TB09k7Q1r4e9bYPMxLvHYYwEYkHtKC2pmGIZhhBI3xikjJYOBnQdCUVDcwp49YfBgmDOnlnxl5W42b36EqqoS8+AzDMPYx0hgYWrboH379lpcXNyoslu3woEHBs5VgSuvhGnTmPm//PC7mQCQyIQJtveTYRhtFxEpUdX2La1HtMS05yQip4rIShFZIyK3h8m/XETyRGSR73V1LPW5887A8Zdf+g7Gj4f8fNI3hy3iwyJHGIZh7EtiZpxEJBF4EpgIDAMuFpFhYURfV9XRvtdzsdLH6eTeExOdTQKqD0bs+T1ZWb+NZfOGYRhGlMSy53QEsEZV16lqBfAacFYM26uXBN/VSvDw3eDB0L076XM3MWjQX1tEL8MwDKMmsTROvYHgwbIcX1ook0TkBxGZKiJ9wuQjIteKyHwRme/xNH7uR8LNKYnAccfB1KmIF3r3Dr8Ad+nSc2hr83OGYRhtlVgap3CmIPTp/h7QX1VHAp8B/wlXkapOUdVxqjouKanx+yP6jVMtI3XGGeDxwCOPkJk5LmzZnTvfQdWcIgzDMPYFsTROOUBwTygL2BIsoKr5qlruO30WGBtDfaqH9Wpx3nnuffp0eva8hCOOWB1WLD//PXMrNwzD2AfE0jh9BwwWkQEikgJcBEwLFhCRoEVHnAksj6E+kXtO6elw/fUwcyZSUUF6+kFhyy9bNonVqyfHUkXDMAyDGBondWNgk4GPcUbnDVVdJiL3iciZPrEbRGSZiCwGbgAuj5U+wYSdezrhBPB64WrnzT58+JthyxYWfhdDzQzDMAzYTxbhVlZWkpOTQ1lZWZ1ld+2CwkJnnPr2DclUhU2b3HG/fgBUVRVSWbkrbF0JCekkJKSSlJTZqOtoLaSmppKVlUVycnJLq2IYRgyJZhGuiJwKPAokAs+p6kMR5M4D/gccrqrzm11ZoPHeBa2InJwcMjMz6d+/PxK2W+TYtAl27HDGaejQMAKdOsGWLdC/P6Sl4fEUUlq6ss62MzPDVdQ2UFXy8/PJyclhwIABLa2OYRgtSNDa1JNxPgPficg0Vc0OkcvEjXR9E0t99ovYemVlZXTt2rVOwwTOMNVJly7uPScHgKSkTETaNYOGrRMRoWvXrvX2OA3DiAuiXZt6P/BXIKYPjv3COAH1GqaashEyUlMhM9ON/fnWU2VkHEpyco+IdXm95RHz2gINuW+GYbRpkvzrRX2va0Py612bKiJjgD6q+n6Mdd1/jFOzkZXlHCMWLfJFhoV27cKuDQaguHjJvtLMMAyjKXj860V9rykh+XWuTRWRBOBh4JZYKunHjFMo7YPmC3c5ZwgRIT09XFhAx549e3jqqaca1dxpp53Gnj17GlXWMAyjGalvbWomMAKYKSIbgKOAaSISPnJBEzHjFI6RI937+vVQ7obtEhPTI4rn5a2PaJyqquqOaD59+nQ6derUOD0NwzCajzrXpqpqgap2U9X+qtofmAecad56UXLTTW5ELhyFhe5dBDIy6qolBcqGQ6UHqGD0+BQeeVRITx9BScnSWtK3334ba9euYfTo0Zx88sn89Kc/5d5776VXr14sWrSI7Oxszj77bDZv3kxZWRk33ngj117rhnv79+/P/PnzKSoqYuLEiYwfP56vv/6a3r178+6775KWllajrffee48HHniAiooKunbtyiuvvELPnj0pKiri+uuvZ/78+YgId999N5MmTeKjjz7ijjvuoKqqim7duvH55583/KYahrHfo6oeEfGvTU0EXvCvTQXmq+q0umtoXvY749RspKZBpc+aeTxAMomJqSQkpOP1ltQQvffeySxfvpZvvplOQkI7vvpqCd9++y1Lly6tdtF+4YUX6NKlC6WlpRx++OFMmjSJrl271qhn9erVvPrqqzz77LNccMEFvPnmm1x66aU1ZMaPH8+8efMQEZ577jn++te/8o9//IP777+fjh07smSJmwPbvXs3eXl5XHPNNcyePZsBAwawa1f4NVuGYRgAqjodmB6SdlcE2Qmx1GW/M06PPBI5b76v8ykCY6OJ4renCtasccee0ZCURHr6wXi9FXi95ZSVra0hXlERGJ494ogj6N+/P6qKiPDYY4/x9ttvA7B582ZWr15dyzgNGDCA0aNHAzB27Fg2bNhQS6WcnBwuvPBCtm7dSkVFRbXx++yzz3jttdeq5Tp37sx7773Hj3/842qZLn5XecMwjFaOzTnVRadO0L27O161CgCRJBIT00lO7hyxWGnpJtq181BUtICysrXMnDmTzz77jLlz57J48WLGjBkTdm1Ru3aBNVWJiYmE2x7k+uuvZ/LkySxZsoRnnnmmuh6/EQwmXJphGEZbwIxTffjjHJWUwM6dYUUyMtIpKgoM9akGIpd7PHsoKCigc+fOpKens2LFCubNm9dodQoKCujd2y09+M9/AjuMnHLKKTzxxBPV57t37+boo49m1qxZrF+/HsCG9QzDaDOYcaoPERg40B1v2ABrA0N5aWkHA9C1ayeOPHIURx55IXfe+WitKiZMGEZ5+R5GjhzBn/70J4466qhGq3PPPfdw/vnnc+yxx9KtW7fq9DvvvJPdu3czYsQIRo0axYwZM+jevTtTpkzh3HPPZdSoUVx44YWNbtcwDGNfsl8Efl2+fDlDwwbLC1BRAT/8EDgf11DP/Jwc2LbNHY8Y4aJJAOXl26ioyGlARYmkpw9BJJni4sWkpQ0mISEN1SoSE1MbqFTzEM39MwyjbRNN4NfWRNz0nCorm1hBVhb07OmOly6F7dsBaNfuANLThzegoipKSpb5PP6UioqtFBf/ENZFvTXj8RTatvWGYcSMuDFOzUKfoMXTmzeDrweXmJhG+/YjSUsbTPS31O+ooITuXl9ZmY/X68HrraSwcH7EbTtaivLyrcyZ04HNm//e0qoYhrGfYsapoRx2WOB4+fLqob6EhBSSkjqSkTEmqmr8W3FUVRVVp1VU7KCwcD5lZespKcmuDipbUbEdVaWqqoTy8m0+g7WTqqpSCgvnU1VVSnl5Lh5PUY02PJ4iKirymnK1YSkvzwVgx47X6pE0DMNoHHFpnA4Kvwt7dCQk1FwklZPjAsX6aIrrdnn5pupj1QrKytb5z/B4dlFSkl09v1VWtoGyso0AeDy7qKjYSmnpCoqKfqC83MmUlq6gvHxjo/UJxuMpZNeujwFISEj26RgYKy0qWsru3V/UWcfGjQ+xdOk5zaJPW6CwcAGqdYevMgwjPHFpnJocyi50Fe/ChYHYSEBSUifatetLWtohTWrGbakCXm8JZWXra+V7va6nVFGxtUaZioptNeTKy915SckqiouXoaqUleXg9Zaj6sXrda7vhYULWbXqN+zc+S47dkxl5kxh5kxh8eJTmDOnAz/8cCoFBV8FtVXJ9u2vUFVVxvz5h7J48Ym1dCwpWYnHUwDA+vV/YOfOd2rkV1TsZOZMqTZ8qlrnXJbHU8D27a/5rr+S0tJ1EWUbwpYtz5CX93Yd7RZSXr6VoqLFNdLdguzaE5p7985nwYJxbNz4YLPoZzg2bnyQTZv+0tJqGPuA/S5CxD5DBMaMge+/d+crV7qAfQMHkpYW6JplZo6jqqqYkpLl+1S9wsJALMaKihxUK6mq2gtAUdFCQKms3EZCQjoVFTtYvPgn7N79CQBbttQMYrt796fVx99/P776uKRkBcuXX0rnzi/VkN+48SESElJISEhj9errSE8fzujRM6vz16y5mZycR/jxj8ur78sPP5zKwIF/Y926Wxk06GF69bqSyso80tIG1ah7xYor2bnzLTIyDiU39ym2bHmKY47ZQUpK98bfLGDVql8BMGFCeMP49dcHVIetGj++gKSkDgB8+WUHkpO7cOSRa0lMDMRB9Pdei4q+b5JeRk3Wr78TgL59b2thTSKzZ88s2rcfQXJy1/qFjYjEZc+p2UhMrDkHVVTk/NW3bq3eC8qJtad9+1E1ivbq9WMAUlP3zfbolZXbg84CuvkfuH7D1BiCy86cKaxf/wfWrr2F1auvA6CkZBlffx0wHjk5LsbU7NntKCz8tjp93bpbAVi79mbmzOnIN98EjPyWLc8xc6ZQUrLCp3dZdbseT2DLkfnzDyM392mqqlzkjKqqMr7//jhmzhR2755RS/dwc3Kq3lrDccHxFL3e0uqepWo5FRVb+fLLdHbseKPO+1QfHk8BublPV/ccnWOMm3csL8+lqOiHuoqHJS/vLWbOFMrKNkeU8XorKC3dQHHxisYpXg8eTwF798Z0R++oKCiYy5w5namszAcgP396xM1C8/M/orBwYYPbUPWyaNEEFi8+udF6ejx7a80fxyNmnJqKfw6qR9Buubm5sGCBC+bniyqRkJBMWtrBpKYO9LmeC6mpA0lO7kpiYoeW0b0VsHbt7+rM//rrLGbOFFatugaAkpJsALKzL6a01MU9LCxcwPbt/8eOHa9TVPQ9q1f/mi+/TCM//0OWLj2bgoLZACxefAK7d3+Ox1NEcfEyCgq+5uuve7Bp01+r21u8+FRmzUpk1qwkVJWVK69h06aaXol79swkO/v8Wrru3Pk2Hk8RX3+dxbJl5/jS3sHrrSQ//0P27JlVQz4//yNmzhRyctzC7ZUrr2b16l8za5b7WX71VTeWLj2b0tINzJ2bxfz5o1i//m62bn2eRYtOxOPZW+e9W7DgKJYtmwTAvHl9I8qtXv0bvvlmAN99N7TagG/f/gq7dn2GqlJevoXKyny2bXuZdevuxOutoKqqFI+nsFZdlZV7qKzcXX3u9VYwb94gFi48qtoQ7N79ObNmtQvrhbphw73s3fttrXR/XeHTPSxadDy5uU+Rl/dWWJlVq37D998f44vY8hUFBV+zZMlPWbfuj2HllyyZyIIFY1m79nZ2755JcfGyGvmlpWupqNhRq5x/HrYpPeY5czoyd26vRpffX9jvFuHe9NFNLNpWe8+MqioXgQjcTuwNYfQBo3nk1MgRZW+77Tb69evHdZddBitXcs+UKWSmp/PLc8/lrFtuYXdhIZUeDw888ABnnXsueL1kdOtGUVERFBej7ZIpKV+DSAoXXngdubk7KCsr5Ve/msQVV5wLwKeffs199z1FVZWXrl078t57/6KoqIRbb/0b33+/HBHh9tuv4ayzTmjYxQFr1uykoGBig8vt7yQldcbj2V2/YD1kZf2WnJx/AnDooR9QVVVMampfFi4MRArp0uWn7Nr1QfX5oEH/YO3aujccTU3tT1raQQwc+FcKCmazd+93DBv2XwC2bfsvK1ZcVkN++PCpLFt2Hj16/Izy8k30738fixfX/r6MGjWDxYuPj9juwIEPsW7d7QCkpw+jpCSbDh2OYu/eQFiu446rYvv2lyks/J7cXGd8ExLS6d37evLy3qieQx048CEggS1bnmbgwIfIzr4AgF69fklGxqH06nUNoGzYcB+bNv2/6vo7dTqBysodHH74EsrLt9V4mPfuPZmsrJto164vu3Z9RKdOxzNnTuBHP2LEu1RW7mTlyqt8OvyNPn1uqeHMNHNmbcemgw9+hoyMw2jXrhdz52YBMHjwk75hfKFLl5PxeAqZM8f92ezb9w/06PEzqqqKWLXqGrKybqZXryspKVnF0qXnUlKyjAMOuIohQ54jN/dpRBLp1evq6j8nACNHfkrnzic2S4zMtrYI14xTFNRnnL7//ntuuukmZs1y/4yHHXIIH/3jHxzYrRslZWV0yMhg5549HHXFFax+6y1EhIzjjqMoOxvyfMNKw4dDWhq78vPpUllJaVoah//oR8ycOYPS0s0cffREvvjiQwYfNJLduwvokpnJrX+8nYqKCv75z79TUrKU4uL2dC4tprITaOhsohe3tCrMdzzYOKXsBG8yeDrWXcZonfTt+0cyMkaSnd08oar6vQwDXoCZn9Mqx1m6d7+QvLw3CF0r2BgOOugxNm/+R4M9XBMqoPtM2H4y9f5WkisyGfXrQlbeAoW+zbX79fsTGzfeX2e5IUNepKJiOz17Xkq7dgc2SD8/bc047XcOEZGMSHGxW5YEjQhdVA9jxoxhx44dbNmyhby8PDp360bf00+ncs8e7rjlFmbPnk2CCLl5eWzPz+eAbt3cnFRe0HzHMjds8NiUKbw9cyYAm7dtY81775O3ezfHjRrHwXu9sHAR/o0vvnj/Q1578EESF2eTmZ5BZkYG5BeTsksgqzcVaeUkpnVE9hSRuHEb2iEDzepNVdF2ErbtIdE3StKuMIWDU/7IqsoHOcY3WrX1mr70/PcmKrrAvNdd2qF9XyEzWyj+5CmWnD4Hb0rQTfBCcgFUdoaUlAOpqNhCevpQsrJ+S+quJNIe/h8LL/mKyoSCWveve/fzyMubCvjqyKTlH4QKyXuhsmPDi6blQumBVD+oer3njreeXlt22D2QsQ6+fal2XmPYtKn5vAPb5TnDBJBYAlV1btDZdKQCRtwNXefBzqNh6f+rv0xenvtyJhe4V0lfQKH7LNh5DGhK+HIdl0DPT2DLWVDRxb3WrLmhUXof+A4c9C/X7vaf1C2bvryQjHVw0FPwvS9Oc32GCWDFissByMv7H2PHftcoPdsaMTVOInIq8ChuV8XnVPWhkPx2wEvAWCAfuFBVN8RSp1hx3nnnMXXqVLZt28ZFF10EwCvvvENeURELsrNJBvoPGkRZcnLEOmYuWMBn337L3BdeID01lQm//CVlFRVu64ugtVR+qrfE8HqdM0aRm0QVVdicg9uAI2AAZW8Rkr2y1nNfyis48IQHCf4/1utZt+YqdQdMqB7huQSAFODHj4e/Br3hBqR7d/jTn+CbFyHrqGrnkB+91x3yoOT+a0ldsZeEV15D+/ZBXrwOfbQCeddttKkD+qFdOyMJyfCTU+Dpp8n93SGkvf01ecdBQjn0+y9UTTiSwl3fsOOyXgz8/kjKs9Lo8vtXAdg7FCo7QFlPWH0DkAA9PoPCQyChCg6YDut+CZoIA6Z2JH1pAd4k6PkFfP8oZKyBwY/D/GcgdTtkrIWkIlgz2V1n8i7Xu9TEwLWn5cJh1zmjtvJm2Haqezge4kb06DoXdpwIGavdg3H+89DDNw2VWAJJe1075d2g/UYo6QOFQyFlF/T7D6z9NaRuAwRK+rlyHZfA4Edh0T/cPVl/DdV/GqTS3auECuj5uTvecRKUHQCZyyGhEsbcCMtvg6RiyP+Ry0uocO0c8rfAtfWe5sonFcPWidDzM+g13bWxexwsuw8SygCFjtkw6nfww0Ow68hAHUlFUJVW854Fc8DHzjABdJvr6kvZBWW+L2bScLg8owAAC/lJREFUXjjk71BwqLuP3mTwpIMojLsa2u2Eb19wug+/F4r7wYKnwRsmZOWIOyC5CA58H6pS4csPa+an7IKqdjDmelj5eygcAsm7QTxQ4fftqYJBz0Cf/7nToQ9B5mpYfyUc+1PIvtPpCdDjU0gqofoPS0KlK59QCSP+BGt/CcV+/x91cr3ehwHPw9ypkLkS9g6D1NSB4W/efkjMhvVEJBFYBZwM5OD2p79YVbODZK4DRqrqr0TkIuAcVa1zPKKxgV+LimCFzxmpuXtOAMuWLeOaa65h586dzJo1i169evHoo4+yZs0aHn/8cWbMmMEJJ5zA+vXr6d+vHxmZmRRt314dAolNm3h31iyee+cd3nv4YVZs2MDoSy7ho8ceY/jAgRx26aXMnjKFAb17s6uggC4dO3L7449TVlHBI7e4uYnde/fSuUPDnSuW79zJ0Ik259QaKe0FaVvrl2tp1l8OA16snb7pQuj7evgy3vQUyrpWkB7ZkbBZ8KT7DEMdFP10KBkfNP9yDxXQ9FQSimvv39Yoli+HIUMaVbStDevF0jgdDdyjqj/xnf8BQFX/HCTzsU9mrogkAduA7lqHUo01Ttu2uWAOEBvjBHDooYfSrVs3ZsxwHk87d+7kjDPOoLKyktGjR/PVV1/x4Ycf0r9/fzIyMpxDRBDl5eWcffbZ5ObmcshBB5GXl8c999zDhBNO4MO33uKO++/Hq0qPHj349OOPKSop4Te/+Q0LFiwgsaqKu3/9a8694ALXUyktddFugxYHk5xcMwJut26QnMzyFSsYetJJgfTOnd3EXL9+MGwYPPNMbG6YYRgN45BDAv+yG4gZJ3/FIucBp6rq1b7zy4AjVXVykMxSn0yO73ytT2ZnSF3XAtcCpKSkjC0vr7k2oSE9p4EDwXYrr0mjtszweCApwqiw/zslArt21bzhJSVuGDIjaALD63Uu+dGyd68rn5Dgym7a5DaF9Hhce3v2uH+XlZXw1VfOQBcWOq+Ygw925Tdvdgb8wgudvqmp7h9M+/awfj38/vdwww1w+ulO7sYb4eqr3fKAM86ALVtg9GhYvBi+/BJ++Uu3EHvBAtf2ypXQuzekp8P//R/cdJPTs3dv+OYb12bPnpCW5v4trV0Ln3wCP/2pyz/tNJg2zd3jb76BW26BDz901/3999CxIwwdCnPmwOGHu+ULQ4a4e/DFF/DBB/Dzn7v2N26Ea66B8nK49FL3Y0hKgmefhbIyOOkkmDkTBg920U46d4aPPoK//tUdJye7vczuvhuOPdZ9rr/4BTz5pLuvnTu7axwxwl1Xfr67j//7H7RrB+PHw7ffOtlBg9xntWWLu6+bNjm9R46EW29117F8udsFIDnZ/WinTnX3LTMTjjoKCgpcXSed5HaoXrkS3noLbr7ZzeO+/z5ccom7xqlT3TKPDRtg4kTXzl/+Ahdc4D6/pUvd92TpUvfd6dnT3YeePd1rwACn65Yt7nszaRK8+qors3ev0z0lxenXqRM8+iicd577PhUWuu/RiSe6oNFpadChg2v/xRedXmvXunvfsaOr75FH4M9/drKbN7vPvrISduxw38vsbPe5N4JojFMUUzG/An4DVAFFwLXBo2HNSSyN0/nAT0KM0xGqen2QzDKfTLBxOkJV8yPV29iekxEZu3+Gsf9Tn3GKciqmg6ru9R2fCVynqqfGQt9Y+kTlAEF7TJAFbIkk4xvW6wi0rv0hDMMw4oMj4P+3d38xUlZ3GMe/j7CwFoyCrQ0BU4FyUZpYSnthajVNarDSC2xCo7G1RE16A4mmMRGjTY13NbEXTUirjSRYSe0/STdNGovYYLhQRAIoRWRLvVglkqyEViNmgV8vzhk7zu4Mu7PMvn/m+SSTeffs2eF9OO/O2fe875zDcEQcjzSx57PAuuYKjY4pm8fFuIe/jV52Tq8CKyQtlTQHuB0YaqkzBGzI2+uBFztdb+qkap/XKgv/v5lZthhovj1lJJd9iqSNeZTrMaC7++8noWedU0ScBTYBzwNHgD9ExGFJj+bTQYCngCslDQM/ATZ3828NDg4yOjrqN9opighGR0cZHCxmeXgzm1GzJe1revy45fsTfYR43JtqRGyJiOXAA8DDvdhRqMkMEWNjY4yMjHDmzEW6XbOPDA4OsmTJEgY6fP7KzKpvEtecLniHdUv9S4BTEdHFR9UvrBYzRAwMDLB06czM7m1mVlOfXIoB3iFdirmjuYKkFRFxLH/5XeAYPVKLzsnMzKYnIs5KalyKmQVsbVyKAfZFxBCwSdJNwBhwiv/fM3DR1WJYz8zMOqvah3CLnl7TzMxsnMqdOUk6D3zU5Y/PBs5exN0pq37I6Yz14Iwz59KIqMwJSeU6p+mQtC8iejSzXnn0Q05nrAdntHYq04uamVn/cOdkZmal02+d05NF78AM6YeczlgPzmgT6qtrTmZmVg39duZkZmYV4M7JzMxKp286J0nfkXRU0rCkrmY/LwtJb0t6XdIBSfty2UJJOyUdy88Lcrkk/TLnPiRpdbF7PzFJWyWdzKsjN8qmnEnShlz/mKSeTa3SjTYZH5H0Tm7LA5LWNn3vwZzxqKSbm8pLeyxLulrSPyQdkXRY0r25vDZt2SFjrdqycBFR+wdpnqh/AcuAOcBBYGXR+zWNPG8Dn20pewzYnLc3Az/P22uBv5Gmw78OeKXo/W+T6UZgNfBGt5mAhcDx/Lwgby8oOtsFMj4C3D9B3ZX5OJ0LLM3H76yyH8vAImB13r6MtLLqyjq1ZYeMtWrLoh/9cuZ0wRUea2AdsC1vbwNubSp/OpKXgSskLSpiBzuJiJcYvwryVDPdDOyMiPcj4hSwE+jJEtLdaJOxnXXAsxHxcUT8GxgmHcelPpYj4kRE7M/b/yWt5baYGrVlh4ztVLIti9YvndOkVniskAD+Lum1pgXDPh8RJyD98gBX5fIqZ59qpqpm3ZSHtLY2hruoQUZJ1wBfBV6hpm3ZkhFq2pZF6JfOaVIrPFbI9RGxGrgF2Cjpxg5165Yd2meqYtZfAcuBVcAJ4PFcXumMkuYDfwbui4j/dKo6QVklck6QsZZtWZR+6ZxGgKubvl4CvFvQvkxbRLybn08CO0jDA+81huvy88lcvcrZp5qpclkj4r2IOBcR54HfkNoSKpxR0gDpTXt7RDyXi2vVlhNlrGNbFqlfOqdPVniUNIe0wuNQwfvUFUnzJF3W2AbWAG+Q8jTuaNoA/CVvDwE/yndFXQecbgyvVMBUMz0PrJG0IA+prMllpdVy/e97pLaElPF2SXOVViZdAeyl5MeyJAFPAUci4hdN36pNW7bLWLe2LFzRd2TM1IN0V9BbpLtjHip6f6aRYxnprp6DwOFGFuBKYBdp2eRdwMJcLmBLzv068PWiM7TJ9TvSUMgY6S/Ke7rJBNxNuuA8DNxVdK5JZPxtznCI9Ma0qKn+QznjUeCWKhzLwDdJQ1OHgAP5sbZObdkhY63asuiHpy8yM7PS6ZdhPTMzqxB3TmZmVjrunMzMrHTcOZmZWem4czIzs9Jx52Q2gyR9S9Jfi94Ps7Jz52RmZqXjzslsApJ+KGlvXpfnCUmzJH0g6XFJ+yXtkvS5XHeVpJfzhJ87mtYq+qKkFyQdzD+zPL/8fEl/kvSmpO15xgEza+LOyayFpC8Bt5Em2F0FnAN+AMwD9keadHc38LP8I08DD0TEtaQZAhrl24EtEfEV4Buk2SEgzWJ9H2mdn2XA9T0PZVYxs4veAbMS+jbwNeDVfFJzKWmi0vPA73OdZ4DnJF0OXBERu3P5NuCPef7DxRGxAyAizgDk19sbESP56wPANcCe3scyqw53TmbjCdgWEQ9+qlD6aUu9TnN/dRqq+7hp+xz+PTQbx8N6ZuPtAtZLugpA0kJJXyD9vqzPde4A9kTEaeCUpBty+Z3A7kjr+4xIujW/xlxJn5nRFGYV5r/YzFpExD8lPUxabfgS0iziG4EPgS9Leg04TbouBWkJiF/nzuc4cFcuvxN4QtKj+TW+P4MxzCrNs5KbTZKkDyJiftH7YdYPPKxnZmal4zMnMzMrHZ85mZlZ6bhzMjOz0nHnZGZmpePOyczMSsedk5mZlc7/AHXuYcySWLrqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 1.0000000e+00 3.2243157e-08]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 인풋값이 다음과 같은 sample이 존재\n",
    "sample=[[5.7, 3.8, 1.7, 0.3]]\n",
    "\n",
    "# 각 클래스 레이블일 확률은?\n",
    "y_pred_prob = model.predict_proba(sample)\n",
    "print(y_pred_prob)\n",
    "\n",
    "# 확률이 가장 높은 클래스는?\n",
    "y_pred_class=model.predict_classes(sample)\n",
    "print(y_pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
